{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c88db3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.00515\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "location_videofile = \"Debate_Talking_Trim5min.mp4\"\n",
    "mp4_file = location_videofile\n",
    "wav_filename = location_videofile\n",
    "track = AudioSegment.from_file(mp4_file,  format= 'mp4')\n",
    "file_handle = track.export(wav_filename, format= 'wav')\n",
    "\n",
    "\n",
    "#  #mp3_audio = AudioSegment.from_file(r\"Debate_Talking_Trim5min.wav\", format=\"wav\")\n",
    "# from pydub import AudioSegment\n",
    "# from pydub.playback import play  \n",
    "wav_audio = AudioSegment.from_file(mp4_file, format=\"wav\")\n",
    "# # print(\"----------Before Conversion--------\")\n",
    "# # print(\"Frame Rate\", mp3_audio.frame_rate)\n",
    "# # print(\"Channel\", mp3_audio.channels)\n",
    "# # print(\"Sample Width\",mp3_audio.sample_width)\n",
    "# # # Change Frame Rate\n",
    "wav_audio = wav_audio.set_frame_rate(16000)\n",
    "# # # Change Channel\n",
    "wav_audio = wav_audio.set_channels(1)\n",
    "# # # Change Sample Width\n",
    "wav_audio = wav_audio.set_sample_width(2)\n",
    "# # # Export the Audio to get the changed \n",
    "wav_audio.export(wav_filename, format =\"wav\")\n",
    "# #print(mp3_audio.frame_rate)\n",
    "\n",
    "#new_mp3_audio= mp3_audio + 10 # increase volume of audio\n",
    "print(len(wav_audio)/(1000*60))\n",
    "\n",
    "\n",
    "# 12 Minutes audio breaks into 3 minutes 4 audio files (slicing is done by milliseconds)\n",
    "\n",
    "# if(counter_audio>=60)\n",
    "# counter_audio = 60\n",
    "# split_audio = [mp3_audio[:60*1000]]\n",
    "# for i in range(4):\n",
    "#     split_audio.append(mp3_audio[counter_audio*1000:(counter_audio+60)*1000])\n",
    "#     counter_audio += 60\n",
    "\n",
    "# else if(counter_audio<=120)\n",
    "\n",
    "#if(len(mp3_audio):\n",
    "counter_audio = 120\n",
    "split_audio = [wav_audio[:120*1000]]\n",
    "for i in range(4):\n",
    "    split_audio.append(wav_audio[counter_audio*1000:(counter_audio+120)*1000])\n",
    "    counter_audio += 120\n",
    "\n",
    "count = 0\n",
    "# # lets save it!\n",
    "for count, audio_object in enumerate(split_audio):\n",
    "    count += 1\n",
    "    with open(f\"{count}_filename.wav\", 'wb') as out_f:\n",
    "        audio_object.export(out_f, format='wav')\n",
    "\n",
    "print(wav_audio.frame_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94737332",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1082e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_of_text = []\n",
    "for i in range(4):\n",
    "\n",
    "    speech, sr = librosa.load(f\"{i+1}_filename.wav\" , sr=16000)\n",
    "\n",
    "    input_values = tokenizer(speech, return_tensors='pt').input_values\n",
    "    # Store logits (non-normalized predictions)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    # Store predicted id's\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    # decode the audio to generate text\n",
    "    # Passing the prediction to the tokenzer decode to get the transcription\n",
    "    transcription = tokenizer.batch_decode(predicted_ids)[0]\n",
    "    # transcriptions = tokenizer.decode(predicted_ids[0])\n",
    "    print(transcription)\n",
    "    collection_of_text.append(transcription)\n",
    "\n",
    "print(collection_of_text)\n",
    "final_complete_speech = \"\"\n",
    "\n",
    "# convert batch of text into one complete sentence\n",
    "for i in collection_of_text:\n",
    "    final_complete_speech += i\n",
    "\n",
    "print(final_complete_speech)\n",
    "\n",
    "with open('recognized.txt',mode ='w') as file: \n",
    "    file.write(\"Recognized Speech:\") \n",
    "    file.write(\"\\n\") \n",
    "    file.write(final_complete_speech) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ae04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read as read_wavs\n",
    "sampling_rate, data=read_wavs(\"C:/Users/Razai/1_wav_filename.wav\")\n",
    "print (sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59668a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub.utils import mediainfo\n",
    "info=mediainfo(\"1_wav_filename.wav\")\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cbf07a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
