{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d1343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63317cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(htmldata): \n",
    "      \n",
    "    try:\n",
    "        with open(htmldata, 'r',encoding='utf-8') as f:\n",
    "            data = f.read()\n",
    "        return data\n",
    "      \n",
    "    except IOError:\n",
    "        print(\"Error opening or reading input file: \", htmldata)\n",
    "        sys.exit()\n",
    "  \n",
    "# splitting the text lines into words\n",
    "# translation table is a global variable\n",
    "# mapping upper case to lower case and\n",
    "# punctuation to spaces\n",
    "translation_table = str.maketrans(string.punctuation+string.ascii_uppercase,\n",
    "                                     \" \"*len(string.punctuation)+string.ascii_lowercase)\n",
    "       \n",
    "# returns a list of the words\n",
    "# in the file\n",
    "def get_words_from_line_list(text): \n",
    "      \n",
    "    text = text.translate(translation_table)\n",
    "    word_list = text.split()\n",
    "      \n",
    "    return word_list\n",
    "  \n",
    "  \n",
    "# counts frequency of each word\n",
    "# returns a dictionary which maps\n",
    "# the words to  their frequency.\n",
    "def count_frequency(word_list): \n",
    "      \n",
    "    D = {}\n",
    "      \n",
    "    for new_word in word_list:\n",
    "          \n",
    "        if new_word in D:\n",
    "            D[new_word] = D[new_word] + 1\n",
    "              \n",
    "        else:\n",
    "            D[new_word] = 1\n",
    "              \n",
    "    return D\n",
    "  \n",
    "# returns dictionary of (word, frequency)\n",
    "# pairs from the previous dictionary.\n",
    "def word_frequencies_for_file(filename): \n",
    "      \n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "  \n",
    "    print(\"File\", filename, \":\", )\n",
    "    print(len(line_list), \"lines, \", )\n",
    "    print(len(word_list), \"words, \", )\n",
    "    print(len(freq_mapping), \"distinct words\")\n",
    "  \n",
    "    return freq_mapping\n",
    "  \n",
    "  \n",
    "# returns the dot product of two documents\n",
    "def dotProduct(D1, D2): \n",
    "    Sum = 0.0\n",
    "      \n",
    "    for key in D1:\n",
    "          \n",
    "        if key in D2:\n",
    "            Sum += (D1[key] * D2[key])\n",
    "              \n",
    "    return Sum\n",
    "  \n",
    "# returns the angle in radians \n",
    "# between document vectors\n",
    "def vector_angle(D1, D2): \n",
    "    numerator = dotProduct(D1, D2)\n",
    "    denominator = math.sqrt(dotProduct(D1, D1)*dotProduct(D2, D2))\n",
    "    #numerator = math.sqrt(dotProduct(D1, D1)*dotProduct(D2, D2))\n",
    "    #denominator = dotProduct(D1, D2) \n",
    "    return math.acos(numerator / denominator )\n",
    "    #return math.acos(denominator / numerator )\n",
    "      \n",
    "def documentSimilarity(htmldata, htmldata2):\n",
    "      \n",
    "   # filename_1 = sys.argv[1]\n",
    "   # filename_2 = sys.argv[2]\n",
    "    sorted_word_list_1 = word_frequencies_for_file(htmldata)\n",
    "    sorted_word_list_2 = word_frequencies_for_file(htmldata2)\n",
    "    distance = vector_angle(sorted_word_list_1, sorted_word_list_2)\n",
    "      \n",
    "    print(\"The similarity between the documents is: % 0.6f \"% distance)\n",
    "# Driver code\n",
    "documentSimilarity('htmldata.txt', 'htmldata2.txt')                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56e1c879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: % 100.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r\"\\w+\")\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
    "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "\n",
    "def text_to_vector(text):\n",
    "    words = WORD.findall(text)\n",
    "    return Counter(words)\n",
    "\n",
    "def read_file(htmldata): \n",
    "    with open(htmldata, 'r',encoding='utf-8') as f:\n",
    "            data = f.read()\n",
    "            return data\n",
    "\n",
    "def documentSimilarity(htmldata, htmldata2):\n",
    "    text1= htmldata\n",
    "    text2 = htmldata2\n",
    "    vector1 = text_to_vector(text1)\n",
    "    vector2 = text_to_vector(text2)\n",
    "    cosine = get_cosine(vector1, vector2)\n",
    "    print(\"Similarity Score: %\",cosine*100)\n",
    "mydata = read_file(\"htmldata.txt\")\n",
    "mydata2 = read_file(\"htmldata2.txt\")\n",
    "documentSimilarity(mydata,mydata2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b25149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "model = SentenceTransformer('stsb-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f149bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: % 0.5538814067840576\n"
     ]
    }
   ],
   "source": [
    "def read_file(htmldata): \n",
    "    with open(htmldata, 'r',encoding='utf-8') as f:\n",
    "            data = f.read()\n",
    "            return data\n",
    "def documentSimilarity(htmldata, htmldata2):       \n",
    "    file1 = htmldata\n",
    "    file2 = htmldata2\n",
    "# encode sentences to get their embeddings\n",
    "    embedding1 = model.encode(file1, convert_to_tensor=True)\n",
    "    embedding2 = model.encode(file2, convert_to_tensor=True)\n",
    "# compute similarity scores of two embeddings\n",
    "    x = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "    print(\"Similarity Score: %\", x.item())\n",
    "mydata = read_file(\"htmldata.txt\")\n",
    "mydata2 = read_file(\"htmldata2.txt\")\n",
    "documentSimilarity(mydata,mydata2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98840513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
