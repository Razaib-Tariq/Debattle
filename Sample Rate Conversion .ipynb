{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6141c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read as read_wav\n",
    "import os\n",
    "os.chdir('C:/Users/Razai') # change to the file directory\n",
    "sampling_rate, data=read_wav(\"testnew101.wav\") # enter your filename\n",
    "print (sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e82e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile\n",
    "\n",
    "data, samplerate = soundfile.read('testnew101.wav')\n",
    "soundfile.write('testnew101new.wav', data, samplerate, subtype='PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read as read_wav\n",
    "import os\n",
    "os.chdir('C:/Users/Razai') # change to the file directory\n",
    "sampling_rate, data=read_wav(\"testnew101new.wav\") # enter your filename\n",
    "print (sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a60937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "data, samplerate = sf.read('testnew101.wav')\n",
    "sf.write('testnew101new1.wav', data, samplerate, subtype='PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read as read_wav\n",
    "import os\n",
    "os.chdir('C:/Users/Razai') # change to the file directory\n",
    "sampling_rate, data=read_wav(\"testnew101new1.wav\") # enter your filename\n",
    "print (sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub.utils import mediainfo\n",
    "info=mediainfo(\"taken_clip.wav\")\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00437376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read as read_wav\n",
    "import librosa    \n",
    "y, s = librosa.load('Debate_Talking.wav', sr=16000)\n",
    "sampling_rate, data=read_wav(\"Debate_Talking.wav\")\n",
    "print (sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafdeebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment as am\n",
    "sound = am.from_file(\"C:/Users/Razai/testnew101.wav\", format='wav', frame_rate=48000)\n",
    "sound = sound.set_frame_rate(16000)\n",
    "sound.export(\"C:/Users/Razai/16hz.wav\", format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b3b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate, data=read_wav(\"C:/Users/Razai/Debate_Talking.wav\")\n",
    "print (sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment as am\n",
    "sound = am.from_file(\"C:/Users/Razai/11min.wav\", format='wav', frame_rate=48000)\n",
    "sound = sound.set_channels(1)\n",
    "sound = sound.set_frame_rate(16000)\n",
    "sound.export(\"C:/Users/Razai/16hz2.wav\", format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b25580",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate, data=read_wav(\"C:/Users/Razai/textnew16hz11.wav\")\n",
    "print (sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d29094d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': '0', 'codec_name': 'pcm_s16le', 'codec_long_name': 'PCM signed 16-bit little-endian', 'profile': 'unknown', 'codec_type': 'audio', 'codec_tag_string': '[1][0][0][0]', 'codec_tag': '0x0001', 'sample_fmt': 's16', 'sample_rate': '44100', 'channels': '1', 'channel_layout': 'unknown', 'bits_per_sample': '16', 'id': 'N/A', 'r_frame_rate': '0/0', 'avg_frame_rate': '0/0', 'time_base': '1/44100', 'start_pts': 'N/A', 'start_time': 'N/A', 'duration_ts': '30090550', 'duration': '682.325397', 'bit_rate': '705600', 'max_bit_rate': 'N/A', 'bits_per_raw_sample': 'N/A', 'nb_frames': 'N/A', 'nb_read_frames': 'N/A', 'nb_read_packets': 'N/A', 'DISPOSITION': {'default': '0', 'dub': '0', 'original': '0', 'comment': '0', 'lyrics': '0', 'karaoke': '0', 'forced': '0', 'hearing_impaired': '0', 'visual_impaired': '0', 'clean_effects': '0', 'attached_pic': '0', 'timed_thumbnails': '0', 'captions': '0', 'descriptions': '0', 'metadata': '0', 'dependent': '0', 'still_image': '0'}, 'filename': '11minH.wav', 'nb_streams': '1', 'nb_programs': '0', 'format_name': 'wav', 'format_long_name': 'WAV / WAVE (Waveform Audio)', 'size': '60181144', 'probe_score': '99'}\n"
     ]
    }
   ],
   "source": [
    "from pydub.utils import mediainfo\n",
    "info=mediainfo(\"11minH.wav\")\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d46402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "location_videofile = \"C:/Users/Razai/one_to_one_Trim15.mp4\"\n",
    "mp4_file = location_videofile\n",
    "wav_filename = \"textnew16hz11.wav\"\n",
    "track = AudioSegment.from_file(mp4_file,  format= 'mp4')\n",
    "file_handle = track.export(wav_filename, format='wav')\n",
    "sound = AudioSegment.from_file(wav_filename, format='wav', frame_rate=48000)\n",
    "sound = sound.set_frame_rate(16000)\n",
    "sound.export(\"C:/Users/Razai/new16hz11.wav\", format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1071e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5907adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d8bc09",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Audio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-61d4df848d4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'11minH.wav'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mAudio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Audio' is not defined"
     ]
    }
   ],
   "source": [
    "file_name = '11minH.wav'\n",
    "Audio(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc34b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wavfile.read(file_name)\n",
    "framerate = data[0]\n",
    "sounddata = data[1]\n",
    "time = np.arange(0,len(sounddata))/framerate\n",
    "print('Sampling rate:',framerate,'Hz')\n",
    "input_audio , _= librosa.load(file_name, sr=16000)\n",
    "print(input_audio)\n",
    "input_values = tokenizer(input_audio, return_tensors=\"pt\").input_values\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = tokenizer.batch_decode(predicted_ids)[0]\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad2840e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Before Conversion--------\n",
      "Frame Rate 48000\n",
      "Channel 2\n",
      "Sample Width 2\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play  \n",
    "mp3_audio = AudioSegment.from_file(\"Debate_Talking5min.wav\")\n",
    "print(\"----------Before Conversion--------\")\n",
    "print(\"Frame Rate\", mp3_audio.frame_rate)\n",
    "print(\"Channel\", mp3_audio.channels)\n",
    "print(\"Sample Width\",mp3_audio.sample_width)\n",
    "# Change Frame Rate\n",
    "mp3_audio = mp3_audio.set_frame_rate(16000)\n",
    "# Change Channel\n",
    "mp3_audio = mp3_audio.set_channels(1)\n",
    "# Change Sample Width\n",
    "mp3_audio = mp3_audio.set_sample_width(2)\n",
    "# Export the Audio to get the changed \n",
    "mp3_audio.export(\"Debate_Talking5min.wav\", format =\"wav\")\n",
    "print(mp3_audio.frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca7cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
